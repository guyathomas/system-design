Scalability

Harvard web development
- Vertical scaling
	- increasing the power of resources
	- i.e. increased HDD size or ram
	- faces real world constraints such as an upper limit on processor speed. can also be very costly
- Horizontal scaling
	- add more machines or HDD's to the system
	- Can use a load balancer (which will have the public IP) to route the requests to the horizontally scaled servers
	- Load balancing (Free to use HA Proxy)
		- Send based on load, round robin, origin, etc...
			- Problems / gotchyas
				- All systems need to be identical ()
				- Depending on the load balancing technique
					- Round robin
						- Some servers may get uneven load if there are power users.
						- Might get unlucky because some server may get it's requests cached by the browser where as another one's may not
						- Sessions are unique to each machine, so having multiple machines can mean that each machine has it's own unique session (and a user may have to log in multiple times, add items to cart multiple times, etc...)
				- Possible to have a shared HDD for all servers that stores the session state for each client
				- Can store the ID of the server in a cookie
					- If I store the IP address of the server then that is vulnerable because the IP address could change and it's not great to let people know the scheme of our internal IP address
					- Instead store a hash which the load balancer remembers where to route it
					- Will fail if cookies are disabled
- Caching
	- Can be an issue if the info is cached but the value has changed
	- File based caching (craigs list serves a static HTML)
		- Super quick to serve up
		- Redundancy in that every file has the same header, footer, etc... so this increases disk space
		- If you want to change the page, then you need to recreate all of the pages stored in craigs list
	- Memcache
		- Typically much faster, however smaller
		- Cache the queries to the database
		- When near full, could remove last recently used or first added
	- Master and multiple slave databases are useful for systems that are read heavy and not write heavy
		- When there is a read query it can propigate to any of the slaves
		- A write query can perform only on the master (and then the slaves will be updated accordingly)


- CDN's for static files

RAID
- RAID0 (Write half of the data to each of two drives to 'double' the HDD speed)
- RAID1 (Write the exact same data to two HDD's)
- RAID10 (Does both of the above - 4 HDD's)